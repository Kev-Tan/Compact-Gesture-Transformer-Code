{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa8336f",
   "metadata": {},
   "source": [
    "### Hyperparameters and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d16ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\miniconda3\\envs\\revisedTransformer\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import everything that is necessary\n",
    "import os\n",
    "os.environ[\"PYTORCH_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import argparse\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import math\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torch.utils.data import DataLoader\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "from timm import create_model\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5464bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    # Network params\n",
    "    'n_classes': 12,\n",
    "    'pretrained': True,\n",
    "    'n_head': 8,\n",
    "    'dropout_backbone': 0.1,  # dropout2d\n",
    "    'dropout_transformer': 0.5,  # dropout1d\n",
    "    'dff': 1024,  # ff_size\n",
    "    'n_module': 6,\n",
    "    \n",
    "    # Solver params (required by ModuleUtilizer)\n",
    "    'solver': {\n",
    "        'type': 'AdamW',  # or 'Adam', 'SGD', 'RMSProp'\n",
    "        'base_lr': 0.0001,\n",
    "        'weight_decay': 0.0001,\n",
    "        'momentum': 0.9,  # only used for SGD\n",
    "        'lr_policy': 'fixed',  # or 'step', 'multistep', 'exp', 'inv'\n",
    "        'gamma': 0.1,\n",
    "        'stepvalue': [50, 75]  # for multistep policy\n",
    "    },\n",
    "    \n",
    "    # Checkpoint params (required by ModuleUtilizer)\n",
    "    'checkpoints': {\n",
    "        'save_policy': 'best',  # or 'all', 'early_stop'\n",
    "        'save_name': 'gesture_model',\n",
    "        'save_dir': './checkpoints/',\n",
    "        'early_stop': 10  # patience for early stopping\n",
    "    },\n",
    "    \n",
    "    # Other required params\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'dataset': 'Briareo',\n",
    "    'gpu': [0],  # GPU IDs for DataParallel\n",
    "    'resume': None  # Path to checkpoint to resume from, or None\n",
    "}\n",
    "\n",
    "# Decide if we use timm_backbone or not\n",
    "timm_backbone = True\n",
    "model_name = \"resnet18.a1_in1k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e617de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0+cu128\n",
      "True\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch;\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.memory_summary())\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f19545f",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40eaa033",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Briareo(Dataset):\n",
    "    \"\"\"Briareo Dataset class\"\"\"\n",
    "    def __init__(self, configer, path, split=\"train\", data_type='depth', transforms=None, n_frames=30, optical_flow=False):\n",
    "        \"\"\"Constructor method for Briareo Dataset class\n",
    "\n",
    "        Args:\n",
    "            configer (Configer): Configer object for current procedure phase (train, test, val)\n",
    "            split (str, optional): Current procedure phase (train, test, val)\n",
    "            data_type (str, optional): Input data type (depth, rgb, normals, ir)\n",
    "            transform (Object, optional): Data augmentation transformation for every data\n",
    "            n_frames (int, optional): Number of frames selected for every input clip\n",
    "            optical_flow (bool, optional): Flag to choose if calculate optical flow or not\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dataset_path = Path(path)\n",
    "        self.split = split\n",
    "        self.data_type = data_type\n",
    "        self.optical_flow = optical_flow\n",
    "\n",
    "        self.transforms = transforms\n",
    "        self.n_frames = n_frames + 1\n",
    "\n",
    "        print(\"Loading Briareo {} dataset...\".format(split.upper()), end=\" \")\n",
    "        data = np.load(self.dataset_path / \"splits\" / (self.split if self.split != \"val\" else \"train\") /\n",
    "                                    \"{}_{}.npz\".format(data_type, self.split), allow_pickle=True)['arr_0']\n",
    "\n",
    "        # Prepare clip for the selected number of frames n_frame\n",
    "        fixed_data = list()\n",
    "        for i, record in enumerate(data):\n",
    "            paths = record['data']\n",
    "\n",
    "            center_of_list = math.floor(len(paths) / 2)\n",
    "            crop_limit = math.floor(self.n_frames / 2)\n",
    "\n",
    "            start = center_of_list - crop_limit\n",
    "            end = center_of_list + crop_limit\n",
    "            paths_cropped = paths[start: end + 1 if self.n_frames % 2 == 1 else end]\n",
    "            if self.data_type == 'leapmotion':\n",
    "                valid = np.array(record['valid'][start: end + 1 if self.n_frames % 2 == 1 else end])\n",
    "                if valid.sum() == len(valid):\n",
    "                    data[i]['data'] = paths_cropped\n",
    "                    fixed_data.append(data[i])\n",
    "            else:\n",
    "                data[i]['data'] = paths_cropped\n",
    "                fixed_data.append(data[i])\n",
    "            # print(\"Length of cropped data\", len(data[i]['data']))\n",
    "        self.data = np.array(fixed_data)\n",
    "        print(\"done.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        paths = self.data[idx]['data']\n",
    "        label = self.data[idx]['label']\n",
    "\n",
    "        clip = list()\n",
    "        for p in paths:\n",
    "            img = cv2.imread(str(self.dataset_path / p), cv2.IMREAD_COLOR)\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            if self.data_type != \"rgb\":\n",
    "                img = np.expand_dims(img, axis=2)\n",
    "            clip.append(img)\n",
    "\n",
    "        clip = np.array(clip).transpose(1, 2, 3, 0)\n",
    "\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            aug_det = self.transforms.to_deterministic()\n",
    "            clip = np.array([aug_det.augment_image(clip[..., i]) for i in range(clip.shape[-1])]).transpose(1, 2, 3, 0)\n",
    "\n",
    "        clip = torch.from_numpy(clip.reshape(clip.shape[0], clip.shape[1], -1).transpose(2, 0, 1))\n",
    "        label = torch.LongTensor(np.asarray([label]))\n",
    "        return clip.float(), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3c4ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloaders():\n",
    "    dataset_path = \"D:\\School\\Lab\\Compact-Gesture-Transformer-Code\\Briareo_rgb\"\n",
    "    train_loader = DataLoader(Briareo(configer=None, path=dataset_path, data_type=\"rgb\", split=\"train\"), batch_size=8,  shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(Briareo(configer=None, path=dataset_path, data_type=\"rgb\", split=\"test\"), batch_size=8,  shuffle=False, num_workers=0)\n",
    "    val_loader = DataLoader(Briareo(configer=None, path=dataset_path, data_type=\"rgb\", split=\"val\"), batch_size=1,  shuffle=False, num_workers=0)\n",
    "    return train_loader, test_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dc19662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Briareo TRAIN dataset... done.\n",
      "Loading Briareo TEST dataset... done.\n",
      "Loading Briareo VAL dataset... done.\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = build_dataloaders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f3d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "    samples, target = batch\n",
    "    Samples = samples.to('cuda')\n",
    "    print(i, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15bcc9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "def vis_dataset_single_image():\n",
    "\n",
    "    # dataloaders\n",
    "    train_loader, val_loader, test_loader = build_dataloaders()\n",
    "\n",
    "    for split, loader in zip(['train', 'test'], [train_loader, test_loader]):\n",
    "        for idx, (samples, _) in enumerate(loader):\n",
    "            # print(\"len of samples\", len(samples))\n",
    "            print(\"--BATCH: \", idx)\n",
    "            # Iterate through the gestures inside a batch\n",
    "            for idx, images in enumerate(samples): \n",
    "                # 93 frames in a gesture \n",
    "                print(\"--Image:\", idx)\n",
    "                print(len(images))\n",
    "                for idx, frame in enumerate(images):\n",
    "                    print(\"--Frame;\", idx)\n",
    "                    print(frame.size())\n",
    "                    image = np.squeeze(frame)\n",
    "                    plt.imshow(image)\n",
    "                    plt.show()\n",
    "                    print(type(image))\n",
    "            return\n",
    "                \n",
    "\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e2ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Briareo TRAIN dataset... done.\n",
      "Loading Briareo TEST dataset... done.\n",
      "Loading Briareo VAL dataset... done.\n"
     ]
    }
   ],
   "source": [
    "vis_dataset_single_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165a80c",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e317b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def position_embedding(input, d_model):\n",
    "    input = input.view(-1, 1)\n",
    "    dim = torch.arange(d_model // 2, dtype=torch.float32, device=input.device).view(1, -1)\n",
    "    sin = torch.sin(input / 10000 ** (2 * dim / d_model))\n",
    "    cos = torch.cos(input / 10000 ** (2 * dim / d_model))\n",
    "\n",
    "    out = torch.zeros((input.shape[0], d_model), device=input.device)\n",
    "    out[:, ::2] = sin\n",
    "    out[:, 1::2] = cos\n",
    "    return out\n",
    "\n",
    "def sinusoid_encoding_table(max_len, d_model):\n",
    "    pos = torch.arange(max_len, dtype=torch.float32)\n",
    "    out = position_embedding(pos, d_model)\n",
    "    return out\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Scaled dot-product attention\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_k, d_v, h):\n",
    "        \"\"\"\n",
    "        :param d_model: Output dimensionality of the model\n",
    "        :param d_k: Dimensionality of queries and keys\n",
    "        :param d_v: Dimensionality of values\n",
    "        :param h: Number of heads\n",
    "        \"\"\"\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.fc_q = nn.Linear(d_model, h * d_k)\n",
    "        self.fc_k = nn.Linear(d_model, h * d_k)\n",
    "        self.fc_v = nn.Linear(d_model, h * d_v)\n",
    "        self.fc_o = nn.Linear(h * d_v, d_model)\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.h = h\n",
    "\n",
    "        self.init_weights(gain=1.0)\n",
    "\n",
    "    def init_weights(self, gain=1.0):\n",
    "        nn.init.xavier_normal_(self.fc_q.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.fc_k.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.fc_v.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.fc_o.weight, gain=gain)\n",
    "        nn.init.constant_(self.fc_q.bias, 0)\n",
    "        nn.init.constant_(self.fc_k.bias, 0)\n",
    "        nn.init.constant_(self.fc_v.bias, 0)\n",
    "        nn.init.constant_(self.fc_o.bias, 0)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        \"\"\"\n",
    "        Computes\n",
    "        :param queries: Queries (b_s, nq, d_model)\n",
    "        :param keys: Keys (b_s, nk, d_model)\n",
    "        :param values: Values (b_s, nk, d_model)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        b_s, nq = queries.shape[:2]\n",
    "        nk = keys.shape[1]\n",
    "        q = self.fc_q(queries).view(b_s, nq, self.h, self.d_k).permute(0, 2, 1, 3)  # (b_s, h, nq, d_k)\n",
    "        k = self.fc_k(keys).view(b_s, nk, self.h, self.d_k).permute(0, 2, 3, 1)  # (b_s, h, d_k, nk)\n",
    "        v = self.fc_v(values).view(b_s, nk, self.h, self.d_v).permute(0, 2, 1, 3)  # (b_s, h, nk, d_v)\n",
    "\n",
    "        att = torch.matmul(q, k) / np.sqrt(self.d_k)  # (b_s, h, nq, nk)\n",
    "\n",
    "        att = torch.softmax(att, -1)\n",
    "\n",
    "        out = torch.matmul(att, v).permute(0, 2, 1, 3).contiguous().view(b_s, nq, self.h * self.d_v)  # (b_s, nq, h*d_v)\n",
    "        out = self.fc_o(out)  # (b_s, nq, d_model)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head attention layer with Dropout and Layer Normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_k, d_v, h, dff=2048, dropout=.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(d_model=d_model, d_k=d_k, d_v=d_v, h=h)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        # self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.fc = nn.Sequential(*[nn.Linear(d_model, dff), nn.ReLU(inplace=True), nn.Dropout(p=dropout),\n",
    "                                  nn.Linear(dff, d_model)])\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        att = self.attention(queries, keys, values)\n",
    "        att = self.dropout(att)\n",
    "        # att = self.layer_norm(queries + att)\n",
    "        att = self.fc(att)\n",
    "        att = self.dropout(att)\n",
    "        return self.layer_norm(queries + att)\n",
    "\n",
    "class EncoderSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, d_k, d_v, n_head, dff=2048, dropout_transformer=.1, n_module=6):\n",
    "        super(EncoderSelfAttention, self).__init__()\n",
    "        self.encoder = nn.ModuleList([MultiHeadAttention(d_model, d_k, d_v, n_head, dff, dropout_transformer)\n",
    "                                      for _ in range(n_module)])\n",
    "    def forward(self, x):\n",
    "        in_encoder = x + sinusoid_encoding_table(x.shape[1], x.shape[2]).expand(x.shape).cuda()\n",
    "        for l in self.encoder:\n",
    "            in_encoder = l(in_encoder, in_encoder, in_encoder)\n",
    "        return in_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bca6e5",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62662602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_timm_backbone(model_name=model_name, hyperparams=hyperparams):\n",
    "    print('build_model args')\n",
    "    print(f\"Creating model: {model_name}\")\n",
    "        \n",
    "    if 'vit' in model_name or 'deit' in model_name:\n",
    "        model = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=hyperparams.get('pretrained', False),\n",
    "            pretrained_cfg=None,\n",
    "            pretrained_cfg_overlay=None,\n",
    "            num_classes=0,\n",
    "            drop_rate=hyperparams.get('dropout2d', 0.0),\n",
    "            drop_path_rate=hyperparams.get('drop_path', 0.0),\n",
    "            drop_block_rate=None,\n",
    "            img_size=hyperparams.get('input_size', 224)\n",
    "        )\n",
    "    else:\n",
    "        try:\n",
    "            model = timm.create_model(\n",
    "                model_name,\n",
    "                pretrained=hyperparams.get('pretrained', False),\n",
    "                pretrained_cfg=None,\n",
    "                pretrained_cfg_overlay=None,\n",
    "                num_classes=0,\n",
    "                drop_rate=hyperparams.get('dropout2d', 0.0),\n",
    "                drop_path_rate=hyperparams.get('drop_path', 0.0),\n",
    "                drop_block_rate=None\n",
    "            )\n",
    "        except:\n",
    "            model = timm.create_model(\n",
    "                model_name,\n",
    "                pretrained=hyperparams.get('pretrained', False),\n",
    "                pretrained_cfg=None,\n",
    "                pretrained_cfg_overlay=None,\n",
    "                num_classes=0,\n",
    "                drop_rate=hyperparams.get('dropout2d', 0.0),\n",
    "                drop_path_rate=hyperparams.get('drop_path', 0.0),\n",
    "                drop_block_rate=None\n",
    "            )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a524262",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _GestureTransformer(nn.Module):\n",
    "    \"\"\"Multi Modal model for gesture recognition on 3 channel\"\"\"\n",
    "    def __init__(self, backbone: nn.Module, in_planes: int, out_planes: int,\n",
    "                 pretrained: bool = False, dropout_backbone=0.1,\n",
    "                 **kwargs):\n",
    "        super(_GestureTransformer, self).__init__()\n",
    "        \n",
    "        self.in_planes = in_planes\n",
    "        self.out_planes = out_planes\n",
    "        self.self_attention = EncoderSelfAttention(512, 64, 64, n_head= 8, dropout_transformer= 0.5, dff= 1024, n_module= 6)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 512))\n",
    "        self.classifier = nn.Linear(512, out_planes)\n",
    "        \n",
    "        if(backbone==\"timm\"):\n",
    "            self.backbone = build_timm_backbone() \n",
    "            print(\"Finish building backbone\")\n",
    "            \n",
    "    def forward(self, x):\n",
    "        shape = x.shape\n",
    "\n",
    "        x = x.view(-1, self.in_planes, x.shape[-2], x.shape[-1])\n",
    "\n",
    "        x = self.backbone(x)\n",
    "        x = x.view(shape[0], shape[1] // self.in_planes, -1)\n",
    "\n",
    "        x = self.self_attention(x)\n",
    "\n",
    "        x = self.pool(x).squeeze(dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d353f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(backbone=\"timm\", in_planes = 3, out_planes=12):\n",
    "    model = _GestureTransformer(backbone = \"timm\", in_planes = in_planes, out_planes=out_planes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde0b3f1",
   "metadata": {},
   "source": [
    "### Model Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b8454dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Veryfing the layers through the model\n",
    "# from torchinfo import summary\n",
    "\n",
    "\n",
    "# model = build_model(backbone=\"timm\", in_planes=3, out_planes=12)\n",
    "# model.eval()\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)  # Move model to device\n",
    "\n",
    "# # AI ASSISTED-> I had an issue with moving model and data to the correct device\n",
    "# train_loader, val_loader, test_loader = build_dataloaders()\n",
    "\n",
    "# test_input = next(iter(train_loader))\n",
    "# # Move input to the same device as model\n",
    "# output = model(test_input[0].to(device))\n",
    "\n",
    "# print(\"Input shape: \",test_input[0].shape)\n",
    "# print(\"Output shape\", output.shape)\n",
    "\n",
    "# # AI ASSISTED -> I wanted to find a quick way to get intermediate layers, and so I use torchsummary\n",
    "# print(\"Intermediate shapes: \")\n",
    "# summary(\n",
    "#     model,\n",
    "#     input_size=(1, 93, 224, 224),\n",
    "#     col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "#     depth=5\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979671ec",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36e4dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "class ModuleUtilizer(object):\n",
    "    \"\"\"Module utility class\n",
    "\n",
    "    Attributes:\n",
    "        configer (Configer): Configer object, contains procedure configuration.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, configer):\n",
    "        \"\"\"Class constructor for Module utility\"\"\"\n",
    "        self.configer = configer\n",
    "        self.device = self.configer.get(\"device\")\n",
    "\n",
    "        self.save_policy = self.configer.get(\"checkpoints\", \"save_policy\")\n",
    "        if self.save_policy in [\"early_stop\", \"earlystop\"]:\n",
    "            self.save = self.early_stop\n",
    "        elif self.save_policy == \"all\":\n",
    "            self.save = self.save_all\n",
    "        else:\n",
    "            self.save = self.save_best\n",
    "\n",
    "        self.best_accuracy = 0\n",
    "        self.last_improvement = 0\n",
    "\n",
    "    def update_optimizer(self, net, iters):\n",
    "        \"\"\"Load optimizer and adjust learning rate during training, if using SGD.\n",
    "\n",
    "                Args:\n",
    "                    net (torch.nn.Module): Module in use\n",
    "                    iters (int): current iteration number\n",
    "\n",
    "                Returns:\n",
    "                    optimizer (torch.optim.optimizer): PyTorch Optimizer\n",
    "                    lr (float): Learning rate for training procedure\n",
    "\n",
    "        \"\"\"\n",
    "        optim = self.configer.get('solver', 'type')\n",
    "        decay = self.configer.get('solver', 'weight_decay')\n",
    "\n",
    "        if optim == \"Adam\":\n",
    "            print(\"Using Adam.\")\n",
    "            lr = self.configer.get('solver', 'base_lr')\n",
    "            optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr,\n",
    "                                         weight_decay=decay)\n",
    "\n",
    "        elif optim == \"AdamW\":\n",
    "            lr = self.configer.get('solver', 'base_lr')\n",
    "            optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, net.parameters()), lr=lr,\n",
    "                                          weight_decay=decay)\n",
    "\n",
    "        elif optim == \"RMSProp\":\n",
    "            lr = self.configer.get('solver', 'base_lr')\n",
    "            optimizer = torch.optim.RMSprop(filter(lambda p: p.requires_grad, net.parameters()), lr=lr,\n",
    "                                            weight_decay=decay)\n",
    "\n",
    "        elif optim == \"SGD\":\n",
    "            print(\"Using SGD\")\n",
    "            policy = self.configer.get('solver', 'lr_policy')\n",
    "\n",
    "            if policy == 'fixed':\n",
    "                lr = self.configer.get('solver', 'base_lr')\n",
    "\n",
    "            elif policy == 'step':\n",
    "                gamma = self.configer.get('solver', 'gamma')\n",
    "                ratio = gamma ** (iters // self.configer.get('solver', 'step_size'))\n",
    "                lr = self.configer.get('solver', 'base_lr') * ratio\n",
    "\n",
    "            elif policy == 'exp':\n",
    "                lr = self.configer.get('solver', 'base_lr') * (self.configer.get('solver', 'gamma') ** iters)\n",
    "\n",
    "            elif policy == 'inv':\n",
    "                power = -self.configer.get('solver', 'power')\n",
    "                ratio = (1 + self.configer.get('solver', 'gamma') * iters) ** power\n",
    "                lr = self.configer.get('solver', 'base_lr') * ratio\n",
    "\n",
    "            elif policy == 'multistep':\n",
    "                lr = self.configer.get('solver', 'base_lr')\n",
    "                for step_value in self.configer.get('solver', 'stepvalue'):\n",
    "                    if iters >= step_value:\n",
    "                        lr *= self.configer.get('solver', 'gamma')\n",
    "                    else:\n",
    "                        break\n",
    "            else:\n",
    "                raise NotImplementedError('Policy:{} is not valid.'.format(policy))\n",
    "\n",
    "            optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr = lr,\n",
    "                                        momentum=self.configer.get('solver', 'momentum'), weight_decay=decay)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Optimizer: {} is not valid.'.format(optim))\n",
    "\n",
    "        return optimizer, lr\n",
    "\n",
    "    def load_net(self, net):\n",
    "        \"\"\"Loading net method. If resume is True load from provided checkpoint, if False load new DataParallel\n",
    "\n",
    "                Args:\n",
    "                    net (torch.nn.Module): Module in use\n",
    "\n",
    "                Returns:\n",
    "                    net (torch.nn.DataParallel): Loaded Network module\n",
    "                    iters (int): Loaded current iteration number, 0 if Resume is False\n",
    "                    epoch (int): Loaded current epoch number, 0 if Resume is False\n",
    "                    optimizer (torch.nn.optimizer): Loaded optimizer state, None if Resume is False\n",
    "\n",
    "        \"\"\"\n",
    "        iters = 0\n",
    "        epoch = 0\n",
    "        optimizer = None\n",
    "        if self.configer.get('resume') is not None:\n",
    "            print('Restoring checkpoint: ', self.configer.get('resume'))\n",
    "            checkpoint_dict = torch.load(self.configer.get('resume'))\n",
    "            # Remove \"module.\" from DataParallel, if present\n",
    "            checkpoint_dict['state_dict'] = {k[len('module.'):] if k.startswith('module.') else k: v for k, v in\n",
    "                                             checkpoint_dict['state_dict'].items()}\n",
    "            net.load_state_dict(checkpoint_dict['state_dict'])\n",
    "            iters = checkpoint_dict['iter'] if 'iter' in checkpoint_dict else 0\n",
    "            optimizer = checkpoint_dict['optimizer'] if 'optimizer' in checkpoint_dict else None\n",
    "            epoch = checkpoint_dict['epoch'] if 'epoch' in checkpoint_dict else None\n",
    "        net = nn.DataParallel(net, device_ids=self.configer.get('gpu')).to(self.device)\n",
    "        return net, iters, epoch, optimizer\n",
    "\n",
    "    def _save_net(self, net, optimizer, iters, epoch, all=False):\n",
    "        \"\"\"Saving net state method.\n",
    "\n",
    "                Args:\n",
    "                    net (torch.nn.Module): Module in use\n",
    "                    optimizer (torch.nn.optimizer): Optimizer state to save\n",
    "                    iters (int): Current iteration number to save\n",
    "                    epoch (int): Current epoch number to save\n",
    "\n",
    "        \"\"\"\n",
    "        state = {\n",
    "            'iter': iters,\n",
    "            'epoch': epoch,\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        checkpoints_dir = str(Path(self.configer.get('checkpoints', 'save_dir')) / self.configer.get(\"dataset\"))\n",
    "        if not os.path.exists(checkpoints_dir):\n",
    "            os.makedirs(checkpoints_dir)\n",
    "        if all:\n",
    "            latest_name = '{}_{}.pth'.format(self.configer.get('checkpoints', 'save_name'), epoch)\n",
    "        else:\n",
    "            latest_name = 'best_{}.pth'.format(self.configer.get('checkpoints', 'save_name'))\n",
    "        torch.save(state, os.path.join(checkpoints_dir, latest_name))\n",
    "\n",
    "    def save_all(self, accuracy, net, optimizer, iters, epoch):\n",
    "        self._save_net(net, optimizer, iters, epoch, all=True)\n",
    "        return accuracy\n",
    "\n",
    "    def save_best(self, accuracy, net, optimizer, iters, epoch):\n",
    "        if accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = accuracy\n",
    "            self._save_net(net, optimizer, iters, epoch)\n",
    "            return self.best_accuracy\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def early_stop(self, accuracy, net, optimizer, iters, epoch):\n",
    "        ret = self.save_best(accuracy, net, optimizer, iters, epoch)\n",
    "        if ret > 0:\n",
    "            self.last_improvement = 0\n",
    "        else:\n",
    "            self.last_improvement += 1\n",
    "        if self.last_improvement >= self.configer.get(\"checkpoints\", \"early_stop\"):\n",
    "            return -1\n",
    "        else:\n",
    "            return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3d70b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_metrics(self, split: str, loss, bs, accuracy=None):\n",
    "    self.losses[split].update(loss, bs)\n",
    "    if accuracy is not None:\n",
    "        self.accuracy[split].update(accuracy, bs)\n",
    "    if split == \"train\" and self.iters % self.save_iters == 0:\n",
    "        self.tbx_summary.add_scalar('{}_loss'.format(split), self.losses[split].avg, self.iters)\n",
    "        self.tbx_summary.add_scalar('{}_accuracy'.format(split), self.accuracy[split].avg, self.iters)\n",
    "        self.losses[split].reset()\n",
    "        self.accuracy[split].reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b621464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove args and replace with device since .ipynb files do not work with command line arguments\n",
    "def train_loop(device, train_loader, model, criterion, optimizer):\n",
    "    # certain modules behave differently during train/test (dropout)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # loss_epoch is similar to running_loss in the PyTorch tutorial\n",
    "    loss_epoch = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for idx, data in enumerate(tqdm(train_loader)):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "        # ChatGPT generated, need clarification on what this means\n",
    "        labels = labels.view(-1).long()\n",
    "        \n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        print(outputs.shape)  # MUST be [B, 12]\n",
    "        # print(model.fc)\n",
    "\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        print(\"Correct Predictions:\", (predicted == labels).sum().item())\n",
    "        \n",
    "        acc_iter = 100 * (predicted == labels).sum().item() / images.shape[0]\n",
    "        print(f'{idx} / {len(train_loader)}, Loss: {loss}, Acc@1: {acc_iter}')\n",
    "\n",
    "    acc = round(100 * correct / total, 2)\n",
    "    return loss_epoch, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d6a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Briareo TRAIN dataset... done.\n",
      "Loading Briareo TEST dataset... done.\n",
      "Loading Briareo VAL dataset... done.\n",
      "build_model args\n",
      "Creating model: resnet18.a1_in1k\n",
      "Finish building backbone\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\miniconda3\\envs\\revisedTransformer\\lib\\site-packages\\torch\\nn\\modules\\module.py:1367: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:39.)\n",
      "  return t.to(\n",
      "  0%|          | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 12])\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = build_dataloaders()\n",
    "model = build_model()\n",
    "criterion = nn.CrossEntropyLoss().to(hyperparams.get(\"device\"))\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001,\n",
    "                                          weight_decay=0.0001)\n",
    "\n",
    "for epoch in range(30):\n",
    "    print(epoch+1)\n",
    "    loss, train_acc = train_loop(hyperparams.get(\"device\"), train_loader, model, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f1bf2f",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67a566f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff45d0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain_model\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_model' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b62f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 23 23:10:04 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.65                 Driver Version: 576.65         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 5060 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   66C    P4             18W /   45W |    1786MiB /   8151MiB |     32%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           29340    C+G   ...s\\Win64\\EpicGamesLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A           47860      C   ...revisedTransformer\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           49564    C+G   ...Heroes Trails to Azure\\ao.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "   !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb39a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python exe: c:\\Users\\USER\\miniconda3\\envs\\revisedTransformer\\python.exe\n",
      "Torch file: c:\\Users\\USER\\miniconda3\\envs\\revisedTransformer\\lib\\site-packages\\torch\\__init__.py\n",
      "Torch version: 2.10.0+cu128\n",
      "CUDA version: 12.8\n",
      "GPU: NVIDIA GeForce RTX 5060 Laptop GPU\n",
      "Capability: (12, 0)\n",
      "CUDA available: True\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch, os, sys\n",
    "\n",
    "print(\"Python exe:\", sys.executable)\n",
    "print(\"Torch file:\", torch.__file__)\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "print(\"Capability:\", torch.cuda.get_device_capability(0))\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "revisedTransformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
